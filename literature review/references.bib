@article{zhong2023ptm,
  author    = {Q. Zhong and X. Xiao and Y. Qiu and Z. Xu and C. Chen and B. Chong and X. Zhao and S. Hai and S. Li and Z. An and L. Dai},
  title     = {Protein posttranslational modifications in health and diseases: Functions, regulatory mechanisms, and therapeutic implications},
  journal   = {MedComm},
  volume    = {4},
  number    = {3},
  pages     = {e261},
  year      = {2023},
  doi       = {10.1002/mco2.261}
}

@article{cheng2023research,
  title={Research progress on post-translational modification of proteins and cardiovascular diseases},
  author={Cheng, XueLi and Wang, Kai and Zhao, Yan and Wang, Kun},
  journal={Cell Death Discovery},
  volume={9},
  number={1},
  pages={275},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{pratyush2024lmcrot,
  title={LMCrot: an enhanced protein crotonylation site predictor by leveraging an interpretable window-level embedding from a transformer-based protein language model},
  author={Pratyush, Pawel and Bahmani, Soufia and Pokharel, Suresh and Ismail, Hamid D and Kc, Dukka B},
  journal={Bioinformatics},
  volume={40},
  number={5},
  pages={btae290},
  year={2024},
  publisher={Oxford University Press}
}


@misc{elnaggar2021prottranscrackinglanguagelifes,
      title={ProtTrans: Towards Cracking the Language of Life's Code Through Self-Supervised Deep Learning and High Performance Computing}, 
      author={Ahmed Elnaggar and Michael Heinzinger and Christian Dallago and Ghalia Rihawi and Yu Wang and Llion Jones and Tom Gibbs and Tamas Feher and Christoph Angerer and Martin Steinegger and Debsindhu Bhowmik and Burkhard Rost},
      year={2021},
      eprint={2007.06225},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2007.06225}, 
}

@article{ferruz2022protgpt2,
  author    = {Noelia Ferruz and Stefan Schmidt and Birte HÃ¶cker},
  title     = {ProtGPT2 is a deep unsupervised language model for protein design},
  journal   = {Nature Communications},
  year      = {2022},
  volume    = {13},
  pages     = {4348},
  doi       = {10.1038/s41467-022-32007-7},
  url       = {https://doi.org/10.1038/s41467-022-32007-7}
}

@misc{dettmers2023qloraefficientfinetuningquantized,
      title={QLoRA: Efficient Finetuning of Quantized LLMs}, 
      author={Tim Dettmers and Artidoro Pagnoni and Ari Holtzman and Luke Zettlemoyer},
      year={2023},
      eprint={2305.14314},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.14314}, 
}

@article{shrestha2024post,
  title={Post-translational modification prediction via prompt-based fine-tuning of a GPT-2 model},
  author={Shrestha, Palistha and Kandel, Jeevan and Tayara, Hilal and Chong, Kil To},
  journal={Nature Communications},
  volume={15},
  number={1},
  pages={6699},
  year={2024},
  publisher={Nature Publishing Group UK London}
}
@article{harrison2017flps,
  title={fLPS: Fast discovery of compositional biases for the protein universe},
  author={Harrison, Paul M},
  journal={Bmc Bioinformatics},
  volume={18},
  number={1},
  pages={476},
  year={2017},
  publisher={Springer}
}

@article{harrison2003method,
  title={A method to assess compositional bias in biological sequences and its application to prion-like glutamine/asparagine-rich domains in eukaryotic proteomes},
  author={Harrison, Paul M and Gerstein, Mark},
  journal={Genome biology},
  volume={4},
  number={6},
  pages={R40},
  year={2003},
  publisher={Springer}
}

@article{messner2023mass,
  title={Mass spectrometry-based high-throughput proteomics and its role in biomedical studies and systems biology},
  author={Messner, Christoph B and Demichev, Vadim and Wang, Ziyue and Hartl, Johannes and Kustatscher, Georg and M{\"u}lleder, Michael and Ralser, Markus},
  journal={Proteomics},
  volume={23},
  number={7-8},
  pages={2200013},
  year={2023},
  publisher={Wiley Online Library}
}

@article{jumper2021highly,
  title={Highly accurate protein structure prediction with AlphaFold},
  author={Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\v{Z}}{\'\i}dek, Augustin and Potapenko, Anna and others},
  journal={nature},
  volume={596},
  number={7873},
  pages={583--589},
  year={2021},
  publisher={Nature Publishing Group UK London}
}


@article{li2022dbptm,
  title={dbPTM in 2022: an updated database for exploring regulatory networks and functional associations of protein post-translational modifications},
  author={Li, Zhongyan and Li, Shangfu and Luo, Mengqi and Jhong, Jhih-Hua and Li, Wenshuo and Yao, Lantian and Pang, Yuxuan and Wang, Zhuo and Wang, Rulan and Ma, Renfei and others},
  journal={Nucleic acids research},
  volume={50},
  number={D1},
  pages={D471--D479},
  year={2022},
  publisher={Oxford University Press}
}

@article{lin2022,
  title={ESM-2: Protein Sequence Embeddings for Downstream Analysis},
  author={Lin, Zhiqing and others},
  journal={Nature Communications},
  volume={13},
  pages={1--9},
  year={2022},
  doi={10.1038/s41467-022-28401-9}
}

@article{elnaggar2023,
  title={Ankh: A Transformer-Based Protein Language Model for Molecular Interaction Prediction},
  author={Elnaggar, Ahmed and others},
  journal={Cell},
  volume={184},
  pages={3712--3725},
  year={2023},
  doi={10.1016/j.cell.2023.03.012}
}
@article{elnaggar2020,
  title={ProtBERT: A Pretrained Deep Learning Model for Protein Sequence Representation},
  author={Elnaggar, Ahmed and others},
  journal={Bioinformatics},
  volume={36},
  number={7},
  pages={2099--2108},
  year={2020},
  doi={10.1093/bioinformatics/btz897}
}

@inproceedings{peng2024ptm,
  title={PTM-Mamba: a PTM-aware protein language model with bidirectional gated Mamba blocks},
  author={Peng, Zhangzhi},
  booktitle={Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
  pages={5475--5478},
  year={2024}
}

@article{madani2020progen,
  title={Progen: Language modeling for protein generation},
  author={Madani, Ali and McCann, Bryan and Naik, Nikhil and Keskar, Nitish Shirish and Anand, Namrata and Eguchi, Raphael R and Huang, Po-Ssu and Socher, Richard},
  journal={arXiv preprint arXiv:2004.03497},
  year={2020}
}

@inproceedings{vaswani2017attention,
  title     = {Attention Is All You Need},
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2017}
}

@article{rives2021scaling,
  title   = {Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences},
  author  = {Rives, Alexander and Meier, Joshua and Sercu, Tom and Goyal, Siddharth and Lin, Zeming and Liu, Jason and Guo, Demi and Ott, Myle and Zitnick, C. Lawrence and Ma, Jerry and Fergus, Rob},
  journal = {Proceedings of the National Academy of Sciences},
  volume  = {118},
  number  = {15},
  year    = {2021},
  doi     = {10.1073/pnas.2016239118}
}

@article{alley2019unirep,
  title   = {Unified rational protein engineering with sequence-based deep representation learning},
  author  = {Alley, Ethan C. and Khimulya, Grigory and Biswas, Surojit S. and AlQuraishi, Mohammed and Church, George M.},
  journal = {Nature Methods},
  volume  = {16},
  number  = {12},
  pages   = {1315--1322},
  year    = {2019},
  doi     = {10.1038/s41592-019-0598-1}
}

@article{wang2017musitedeep,
  title   = {MusiteDeep: a deep-learning framework for general and kinase-specific phosphorylation site prediction},
  author  = {Wang, Duolin and Zeng, Shuai and Xu, Chunhui and Qiu, Wangren and Liang, Yanchun and Joshi, Trupti},
  journal = {Bioinformatics},
  volume  = {33},
  number  = {24},
  pages   = {3909--3916},
  year    = {2017},
  doi     = {10.1093/bioinformatics/btx496}
}

@article{fu2019deepubi,
  title   = {DeepUbi: a deep learning framework for prediction of ubiquitination sites in proteins},
  author  = {Fu, Hongli and Yang, Yingxi and Wang, Xiaobo and Wang, Hui and Xu, Yan},
  journal = {BMC Bioinformatics},
  volume  = {20},
  number  = {1},
  year    = {2019},
  doi     = {10.1186/s12859-019-2677-9}
}

@inproceedings{zaheer2020bigbird,
  title     = {Big Bird: Transformers for Longer Sequences},
  author    = {Zaheer, Manzil and Guruganesh, Guru and Dubey, Avinava and Ainslie, Joshua and Alberti, Chris and Onta\~{n}\'{o}n, Santiago and Pham, Philip and Ravula, Anirudh and Wang, Qifan and Yang, Li and Ahmed, Amr},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2020}
}

@inproceedings{gu2022s4,
  title     = {Efficiently Modeling Long Sequences with Structured State Spaces},
  author    = {Gu, Albert and Dao, Tri},
  booktitle = {International Conference on Learning Representations},
  year      = {2022}
}

@inproceedings{gu2020hippo,
  title     = {HiPPO: Recurrent Memory with Optimal Polynomial Projections},
  author    = {Gu, Albert and Goel, Karan and R{\'e}, Christopher},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2020}
}



